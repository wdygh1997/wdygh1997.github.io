---
title: PyTorch损失函数详解：度量学习
---

# PyTorch损失函数详解：度量学习

<script type="text/javascript" src="/include/head.js"></script>

PyTorch中实现的关于度量问题的损失函数一共有`HingeEmbeddingLoss`、`CosineEmbeddingLoss`、`SoftMarginLoss`、`MultiMarginLoss`、`TripletMarginLoss`、`MarginRankingLoss`、`TripletMarginWithDistanceLoss`、`MultiLabelMarginLoss`、`MultiLabelSoftMarginLoss`九个。

## 度量学习的概念

度量学习是将输入的样本映射到一个输出空间中，在这个输出空间中使用间隔最大化的方法将不同标签的样本分离开来。

度量问题可以分为两种：

1、二元组

$$
Loss =
\left\{
\begin{aligned}
&d(x_a, x_p)&&\text{(正样本对)}\\
&max(0, m - d(x_a, x_n))&&\text{(负样本对)}
\end{aligned}
\right.
$$

2、三元组

$$
Loss = max(0, m - (d(x_a, x_n) - d(x_a, x_p)))
$$

其中，$x_a$表示$anchor$，$x_p$表示$positive$，$x_n$表示$negative$，$d$表示$distance$，$m$表示$margin$。

## `HingeEmbeddingLoss`

## `CosineEmbeddingLoss`



## `SoftMarginLoss`

$$Loss = \frac{1}{N} \Sigma_{n=1}^N l_n$$

其中，

$$l_n = log(1 + e^{- y_n * \hat{y_n}})$$

## `MultiMarginLoss`

$$Loss = \frac{1}{N} \Sigma_{n=1}^N l_n$$

其中，

$$l_n = \Sigma_{c=1}^C max(0, m - (y_{n, c} - \hat{y}_{n, c}))$$

其中，$m$表示$margin$

## `TripletMarginLoss`

$$Loss = \frac{1}{N} \Sigma_{n=1}^N l_n$$

其中，

$$l_n = max(0, m + y_n(\hat{y}_{n,1} - \hat{y}_{n,2}))$$

## `MarginRankingLoss`

$$Loss = \frac{1}{N} \Sigma_{n=1}^N l_n$$

其中，

$$l_n = max(0, m - y_n(\hat{y}_{n,1} - \hat{y}_{n,2}))$$

## `TripletMarginWithDistanceLoss`

## `MultiLabelMarginLoss`

## `MultiLabelSoftMarginLoss`

---

<script type="text/javascript" src="/include/tail.js"></script>
