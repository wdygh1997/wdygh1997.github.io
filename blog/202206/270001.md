---
title: 论文《Deep Interest Evolution Network for Click-Through Rate Prediction》阅读
---

# 论文《Deep Interest Evolution Network for Click-Through Rate Prediction》阅读

<script type="text/javascript" src="/include/head.js"></script>

本文提出了DIEN模型（全称Deep Interest Evolution Network），模型设计了两个模块，其中兴趣提取层（Interest Extractor Layer）负责从用户显式行为中提取潜在瞬时兴趣，兴趣演化层（Interest Evolving Layer）负责建模兴趣随时间的演化过程。

## 用户兴趣

### 挖掘潜在兴趣

大多数的深度CTR模型注重建模域间特征交互，而较少关注用户兴趣表示。其他建模了用户兴趣的模型（如DIN）都将用户显式行为直接视为兴趣，然而潜在兴趣很难通过显式行为充分反映。也就是说，以前的方法都忽略了挖掘显式行为背后真正的用户潜在兴趣。

### 兴趣漂移现象

单个用户的兴趣也是多种多样且不断演化的，用户对不同广告的点击受到的是不同兴趣的影响。

多样性会导致兴趣漂移现象：用户在相邻行为中的兴趣可能迥异，用户某个时刻行为可能依赖于很久以前的行为。演化性是指每个兴趣都是不断演化的，并且有自己的演化轨迹。

## Deep Interest Evolution Network

### Base模型

Base模型为Embedding&MLP结构。

所用特征包括用户信息、用户行为、广告、上下文四类。每类特征都有若干域，每个域中的特征编码为one-hot。所有one-hot向量concat起来，作为模型输入。用户行为特征是$T$个$K$维one-hot向量，$T$是用户行为总数，$K$是用户可点击商品数。

损失函数为：

$$L_{target} = -\frac{1}{N}\sum_{(X,y)\in D}^N (y log p(X) + (1−y) log(1 − p(X)))$$

其中，$X \in D$为神经网络输入，$y \in \lbrace 0, 1 \rbrace$表示是否点击，$D$为训练集，$p(X)$为神经网络输出，代表用户点击广告的预测概率。

### DIEN模型

DIEN采取两步来建模兴趣演化：兴趣提取层（Interest Extractor Layer）基于行为序列提取兴趣序列；兴趣演化层（Interest Evolving Layer）建模与广告相关的兴趣演化过程。

### 兴趣提取层（Interest Extractor Layer）

采用GRU对行为间的依赖关系进行建模：

$$z_t = \sigma(W_z x_t + U_z h_{t−1} + b_z)$$

$$r_t = \sigma(W_r x_t + U_r h_{t−1} + b_r)$$

$$\tilde{h_t} = tanh(W_h x_t + U_h (r_t \odot h_{t−1}) + b_h)$$

$$h_t = (1−z_t) \odot h_{t−1} + z_t \odot \tilde{h_t}$$

其中，$\odot$是逐元素乘积，$W$、$U$是模型参数矩阵。$x_t$是GRU的输入，表示用户的第t个行为，$h_t$是第t个隐藏状态。

然而，仅捕获行为之间依赖关系的隐藏状态 ht 并不能有效地表示兴趣。

由于目标项目的点击行为是由最终兴趣触发的，因此 Ltarget 中使用的标签仅包含监督最终兴趣预测的 ground truth，而历史状态 ht (t < T) 无法获得适当的监督。

众所周知，每一步的兴趣状态直接导致连续的行为。因此我们提出了辅助损失，它使用行为 bt+1 来监督兴趣状态 ht 的学习。

除了使用真正的下一个行为作为正例之外，我们还使用从项目集中采样的负实例，除了被点击的项目。

有 N 对行为嵌入序列：{eib,ˆeib} ∈ DB,i ∈ 1,2,····,N，其中 eib ∈ RT ×nE 表示点击行为序列，ˆeib ∈ RT ×nE 表示负样本序列。

T 是历史行为的数量，nE 是嵌入的维度，eib[t] ∈G 表示用户 i 点击的第 t 个项目的嵌入向量，Gis 是整个项目集。 ^eib[t] ∈G−eib[t] 表示从项目集中采样的项目的嵌入，除了用户 i 在第 t 步点击的项目。辅助损失可以表示为

$$L_{aux} = -\frac{1}{N}(\sum_{i=1}^N \sum_t log\sigma(h_t^i, e_b^i[t+1])+log(1-\sigma(h_t^i,\hat{e}_b^i[t+1])))$$

hit 表示用户 i 的 GRU 的第 t 个隐藏状态。我们在 CTR 模型中使用的全局损失是：

$$L = L_{target} + \alpha L_{aux}$$

其中 α 是平衡兴趣表示和 CTR 预测的超参数。

在辅助损失的帮助下，每个隐藏状态 ht 都具有足够的表现力来表示用户采取行为后的兴趣状态。所有 T 个兴趣点 [h1,h2,···,hT ] 的 concat 组成了兴趣演化层可以对兴趣演化进行建模的兴趣序列。

总的来说，辅助损失的引入有几个优点：从兴趣学习的角度来看，辅助损失的引入有助于 GRU 的每个隐藏状态表示兴趣。至于 GRU 的优化，辅助损失降低了 GRU 对长历史行为序列建模时的反向传播难度。最后但并非最不重要的一点是，辅助损失为嵌入层的学习提供了更多的语义信息，从而产生了更好的嵌入矩阵。

### 兴趣演化层（Interest Evolving Layer）

兴趣演化模块可以为最终兴趣的表示提供更多的相关历史信息。

最好按照兴趣演化趋势来预测目标商品的点击率。

值得注意的是，兴趣在进化过程中表现出两个特征：

由于兴趣的多样性，兴趣可以漂移。兴趣漂移对行为的影响是用户可能在一段时间内对某种书籍感兴趣，而在另一时间需要衣服。

尽管兴趣可能会相互影响，但每个兴趣都有自己的演变过程，例如书籍和衣服的演变过程几乎是单独的。我们只关注与目标项目相关的演化过程。

在第一阶段，在辅助损失的帮助下，我们获得了兴趣序列的表达性表示。通过分析兴趣演变的特征，将注意力机制的局部激活能力和来自 GRU 的顺序学习能力结合以模拟兴趣演变。GRU每一步的局部激活可以增强相对兴趣的影响，减弱兴趣漂移的干扰，有助于建模相对于目标项目的兴趣演化过程。

类似于方程式中所示的公式。 (2-5)，我们使用 i't, h't 来表示兴趣演化模块中的输入和隐藏状态，其中第二个 GRU 的输入是兴趣提取器层对应的兴趣状态：i't = ht .最后的隐藏状态 h'T 代表最终的兴趣状态。

---

<script type="text/javascript" src="/include/tail.js"></script>