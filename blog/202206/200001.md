---
title: 论文《Deep Interest Network for Click-Through Rate Prediction》阅读
---

# 论文《Deep Interest Network for Click-Through Rate Prediction》阅读

<script type="text/javascript" src="/include/head.js"></script>

本文提出了DIN模型（全称Deep Interset Network），实现了不同广告场景下用户兴趣Embedding的个性化，并提出了两种训练深度神经网络的技巧。

## CTR模型捕捉用户兴趣

CTR模型（通常是Embedding&MLP结构）通过用户行为序列来获取用户兴趣Embedding（用户行为序列同时包含多种兴趣），传统的CTR模型通过一个固定不变的长度有限的Embedding完成对用户行为序列（也就是用户兴趣）的建模。

缺点在于：

1、对于不同的广告（电子商务网站中的广告就是商品），Embedding都是一样的，不利于不同广告场景下用户个性化兴趣的表达；

2、用户的所有兴趣都被压缩进一个长度有限的Embedding，表达能力有限，如果扩充维度又会导致模型参数量过大，难以训练。

DIN引入激活单元，实现了广告对于用户行为序列的Attention操作（也即用广告Embedding与用户行为序列Embedding计算相似度作为权重，再对用户行为序列Embedding进行加权的sum pooling成为用户兴趣Embedding），通过将用户兴趣Embedding根据不同广告进行个性化的方式，在有限的维度中完成用户兴趣的建模。

## Deep Interset Network

### 特征表示

输入特征是若干个one-hot或multi-hot向量，每个one-hot或multi-hot向量对应一个类别，输入样本是类别中的某个项，则向量中对应维度为1。

### 基本模型Embedding&MLP

Embedding层：Embedding层参数矩阵随机初始化，根据输入的one-hot或multi-hot向量进行lookup操作。如果是one-hot向量，lookup之后是单个Embedding向量；如果是multi-hot向量，lookup之后是多个Embedding向量。

Pooling层和Concat层：对于用户和广告Embedding，不会存在维度不一致的情况。但是对于用户行为序列Embedding，由于不同用户的行为数不一致，lookup之后的Embedding向量数量也不一样，如果直接concat会导致不同样本的维度不一致，一般是对用户行为序列的所有Embedding向量做sum pooling/average pooling，保证维度一致。最后将用户、广告、行为序列的Embedding全部concat起来送入MLP。

MLP：Embedding送入神经网络，自动学习特征的组合交互。

Loss：损失函数采用二元交叉熵。

### DIN模型

DIN模型区别于Embedding&MLP基本模型的地方在于：

Embedding&MLP基本模型从用户行为序列中提取用户兴趣的Embedding的方式是通过pooling层得到一个固定长度的Embedding向量，无论此时的广告是什么，这个Embedding都是一样的；

而DIN模型考虑用户行为序列与广告的相关性，自适应地计算出在不同广告场景下不同的用户兴趣Embedding。

实现的方法是引入一个激活单元（Activation Unit）来实现Attention操作，激活单元计算广告Embedding与用户行为序列Embedding的相似度作为权重，再对用户行为序列Embedding进行加权的sum pooling成为用户兴趣Embedding。

激活单元的输入是两个Embedding向量：广告Embedding、用户行为序列Embedding。然后计算两个Embedding向量的element wise product获得一个相似度向量，再将相似度向量和输入的两个Embedding向量concat起来过几个全连接层输出一个权重值。

与机器翻译中的Attention不同的是，这里的Attention不会对权重进行softmax归一，好处在于可以用权重的数值大小体现用户兴趣的强度大小。

## 训练技巧



---

<script type="text/javascript" src="/include/tail.js"></script>