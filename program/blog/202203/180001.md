---
title: PyTorch损失函数详解：概率模型与回归问题
---

# PyTorch损失函数详解：概率模型与回归问题

<script type="text/javascript" src="/include/head.js"></script>

PyTorch中实现的关于回归问题的损失函数一共有`L1Loss`、`MSELoss`、`HuberLoss`、`SmoothL1Loss`、`GaussianNLLLoss`、`PoissonNLLLoss`六个。

## 从极大似然估计说起

神经网络得到输入后，输出的是一个概率分布，即每个可能的输出的概率，然后将真实标签带入概率分布得到含有待估参数的概率，进而计算似然函数，作极大似然估计；

对于分类问题来讲，可以直接生成每个类别的概率得到分布；对于回归问题来讲，并不能像分类问题那样直接生成分布，只能生成分布（如Laplace分布，Gaussian分布）的参数，然后再做极大似然估计；如果使用的分布是Laplace分布就是MAE损失函数，如果使用的分布是Gaussian分布就是MSE损失函数。

## `MSELoss`

本意是Mean Square Error平均平方误差，但可以通过设定`reduction`参数来决定是否取平均，如果是默认取平均数：

$$Loss = \frac{1}{N} \sum_{n=1}^N (y_n - \hat{y_n})^2$$

从原理上说，是期望$\mu$为$\hat{y_n}$、方差$\sigma^2$为1的Gaussian分布的负对数似然，再去掉常数项

## `L1Loss`

本意是Mean Absolute Error平均绝对误差，但可以通过设定`reduction`参数来决定是否取平均，如果是默认取平均数：

$$Loss = \frac{1}{N} \sum_{n=1}^N |y_n - \hat{y_n}|$$

从原理上说，是$\mu$为$\hat{y_n}$、$b$为1的Laplace分布的负对数似然，再去掉常数项

## `HuberLoss`

是MSE和MAE的组合，可以通过设定`reduction`参数来决定是否取平均，但默认是取平均数：

$$Loss = \frac{1}{N} \sum_{n=1}^N l_n$$

其中，

$$
l_n = 
\left\{
\begin{aligned}
    &0.5(y_n - \hat{y_n})^2, && |y_n - \hat{y_n}|<\delta\\
    &\delta (|y_n - \hat{y_n}| - 0.5\delta), && otherwise
\end{aligned}
\right.
$$

## `SmoothL1Loss`

是MSE和MAE的组合，可以通过设定`reduction`参数来决定是否取平均，但默认是取平均数：

$$Loss = \frac{1}{N} \sum_{n=1}^N l_n$$

其中，

$$
l_i = 
\left\{
\begin{aligned}
    &0.5(y_i - \hat{y_i})^2 / \beta, && |y_i - \hat{y_i}|<\beta\\
    &|y_i - \hat{y_i}| - 0.5\beta, && otherwise
\end{aligned}
\right.
$$

## `GaussianNLLLoss`

本意是Gaussian分布的负对数似然，但可以通过设定`reduction`参数来决定是否取平均，如果是默认取平均数：

$$Loss = \frac{1}{N} \sum_{n=1}^N l_n$$

其中，

$$l_n = \frac{1}{2}(log(max(\sigma^2, \epsilon)) + \frac{(\hat{y_n}-y_n)^2}{max(\sigma^2, \epsilon)}) + C$$

此损失函数在计算时，需要给定$\sigma^2$，$\epsilon$用来限制$\sigma^2$防止为$0$

## `PoissonNLLLoss`

本意是Poisson分布的负对数似然，但可以通过设定`reduction`参数来决定是否取平均，如果是默认取平均数：

$$Loss = \frac{1}{N} \sum_{n=1}^N l_n$$

其中，

$$l_n = \hat{y_n} - y_n log(\hat{y_n}) + log(y_n!)$$

Poisson分布随机变量的取值范围是自然数，所以需要$\hat{y_n} > 0$，不过可以通过设定`log_input`参数来决定是否输出${\hat{y_n} }' = log(\hat{y_n})$，则${\hat{y_n} }'$取值可以为实数：

$$l_n = e^{ {\hat{y_n} }'} - y_n{\hat{y_n} }' + log(y_n!)$$

---

<script type="text/javascript" src="/include/tail.js"></script>
